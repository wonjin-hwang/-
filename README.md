# 행정안전부 청년인턴 데이터분석사례 - 먼저찾는 비판기사, 먼저뛰는 감찰대응

행정안전부 청년인턴 기간동안 진행한 프로젝트 내용입니다.

PPT 내용에 첨부되어있는 데이터를 제외한 모든 데이터(ex:신문사리스트,키워드)는 행정안전부 보안정책상 공개할 수 없습니다.

PPT에 신문사 갯수는 오타이므로 후에 정정할 것

발표영상:https://www.youtube.com/watch?v=4oVJm8bBV54&t=289s


프로젝트의 문제해결 프로세스
## 1.쉽게 얘기하면 "검색엔진을 만들어라" 라는 클라이언트(복무감찰담당관)의 요구를 우리의 역량에서 어떻게 구현할 것인가.

검색엔진을 만드는 것은 사실상 불가능하다->

예비 조사 후 그나마 가능한 것이 웹 크롤링이라고 판단하였다.->

일단 크롤링을 모르기에 크롤링을 공부한다.->

selenium과 bs4의 사용법을 학습하였다.->

실제 신문사에 bs4를 적용해보았는데 적용이 안되는 신문사가 많다.(url문제/동적,정적개념)->

이러한 신문사는 어떻게 처리할 것인지 논의,고민하였다.->

### 1차결론으로는 bs4로 가능한 신문사는 bs4로, 그렇지 않은 신문사는 selenium으로 크롤링을한다.

                                                                                                        ↓

## 2.몇백개의 사이트를 각각 크롤링해야하는데 가능한 것인가(크롤러에 관한 문제들)?
## 2-1.1에서 냈던 결론으로 진행을 해본다.

2-3명의 인원으로 6개월동안 붙어도 가능할지 미지수이다.->

허나 더욱 효율적인 방법이 없을까?->

일단 selenium과 bs4로 한 지역만 해보자(경북)->

selenium은 bs4에 비하여 시간이 좀 걸린다는 것을 인지했다.->

따라서 프로그램을 구현 후 시간을 체크했다.->

경북만 2시간+@/빈번한 접속차단 이슈 등이 발생->

프로젝트의 목적에 부합하지 않는다.->

### selenium폐기


## 2-2.구글뉴스 홈페이지를 이용해 크롤링한다.

구글 뉴스는 bs4사용이 가능하여 신속하게 크롤링이 가능하고 신문사 지정 기능이 있기에 리스트에 있는 모든 신문사를 불러올 수 있다(고 생각했다.).->

크롤링 코드를 다시 구현하고 구글뉴스(news.google.com)에서 크롤링을 진행한다.->

결과가 이상하다.->

구글뉴스는 기능과는 다르게 안불러오는 신문사가 많고 정확도 또한 떨어진다(공무원이라는 단어를 검색했는데 제목,본문에 공무원이 포함되지 않은 기사 출력)->

몇개의 표본사이트로 신뢰도 측정을 했다.(일치여부확인+출현확인)->

현저히 떨어지는 결과 ->

### 구글뉴스 폐기

## 2-3.bs4를 이용해 크롤링한다.

selenium에 비해 월등히 빠른 크롤링 속도/구글 뉴스에 비해 월등히 정확한 크롤링 성능->

하지만 bs4를 적용할 수 있는 신문사는 약 40% 정도이다.->

각 기사들은 여러개의 신문사에서 중복되는 기사가 있는 경우도 있고/현실적으로 모든 신문사를 크롤링하는 것은 한계가 있다고 판단->

이와 같은 내용을 복무감찰담당관 담당자분들께 보고드리고 협의를 진행->

### 최종결론으로 크롤러는 bs4를 사용하여 만들 것으로 결론


## 2-4. 각 사이트를 전부 크롤링하기엔 각 사이트의 구조가 다르다.

각 사이트의 구조는 전부 다르다고 생각하는 것이 상식적인 사고->

모든 사이트를 일일히 크롤링을 해야 할까? 더 효율적인 방법이 없을까?라는 2-1의 문제가 다시금 재정의->

각자 bs4를 적용할 수 있는 신문사를 선별하고 그 신문사들의 구조를 보고 판단하자->

bs4를 이용할 수 있는 사이트, 그러니까 정적 사이트는 html태그가 매우 유사한 특징을 발견 ->

크게 두개의 태그형식으로 구분되는 것을 확인->

이 구조를 csv파일로 저장하여 반복문으로 고유값만 각각 추출해오면 되지 않을까?->

테스트로 몇개의 사이트를 진행했는데 매우 성공적->

### 각 신문사의 html태그는 공통된 형식이므로 그 값만 따로 저장하고 크롤러는 공통크롤러 2개만 만들면 된다.

## 3. 크롤러는 다 만들었는데 비판기사가 안나온다.

프로젝트의 목적은 비판기사를 빠르게 수집하여 감찰활동을 진행하는 것이 목적->

비판기사에 많이 나오는 단어를 제공받음, 기준은 해당과에서 현재껏 감찰을 진행하며 축적된 경험->

모든 검색어를 전부 한번씩 넣어서 검색하는 것은 1.불필요한 기사도 추출 2.시간문제->

기본키워드+지역키워드+업무키워드 이런식으로 키워드의 교집합을 만족하는 기사만 추출하도록 코드 구현->

문제는 기본키워드 역할을 한 "공무원" 이라는 키워드에서 기사가 안나오면 수집이 불가능->

지속적인 수집실패로 복무감찰담당관에 비판기사 샘플을 요청->

총 xx개의 비판기사를 제공받았고 이 기사의 제목,본문을 토크나이징하고 빈도분석 진행->

빈도가 높은 단어들을 바탕으로 크롤러 테스트(빈도 1위였던 "논란")->

바로 다음날 비판기사 8개 수집->

### 데이터분석을 통하여 유의미한 단어 선택 및 업무 성과 달성(비판기사 수집 성공 및 현업자들에게 정확한 가이드라인 제시)










